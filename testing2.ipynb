{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model... \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "038bcedb45db4d8a864e51b73d244834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, pipeline, AutoModelForCausalLM\n",
    "from transformers import TextStreamer\n",
    "import os\n",
    "import torch\n",
    "\n",
    "model_id = 'llm'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "print(\"Loading Model... \\n\\n\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info_from_ocr(ocr_text):\n",
    "\n",
    "    inst = f\"\"\"Extract the medication name from this OCR text of a medicine package:\n",
    "    {ocr_text} \n",
    "\n",
    "    Return only the generic medication name, manufacturer/laboratory, importer, dosage, and packaging quantity of the OCR text, don't add addresses or any labeling. Write NOT FOUND if any info is missing. Return them seperated by |.\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": inst},\n",
    "    ]\n",
    "    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    input_text=tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "    # Tokenize the sample\n",
    "    inputs = tokenizer([input_text], return_tensors='pt')\n",
    "\n",
    "    # Call generate on the inputs\n",
    "    out = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=96,\n",
    "        streamer=TextStreamer(tokenizer=tokenizer, skip_special_tokens=True),\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        do_sample=False\n",
    "    )\n",
    "\n",
    "    extracted_query = tokenizer.batch_decode(out)[0]\n",
    "    #extracted_query = extracted_query[extracted_query.index('<|im_end|>\\n<|im_start|>system\\n')+len('<|im_end|>\\n<|im_start|>system\\n'):]\n",
    "    #extracted_query = extracted_query.replace('<|im_end|>', '')\n",
    "    extracted_query = extracted_query[len(input_text):]\n",
    "    extracted_query = extracted_query.replace(\"<|im_start|>system\", \"\").replace(\"<|im_end|>\", \"\")\n",
    "    return extracted_query.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system\n",
      "You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\n",
      "user\n",
      "Extract the medication name from this OCR text of a medicine package:\n",
      "    Levothyroxine sodium Euthyrox 50 mcg Tablet Thyroid Hormone Replacement CK R Imported by Merck Inc. 36th Floor,The Finance Center 26th Street corner 9th Avenue, Bonifacio Global City,Taguig 100 Tablets MERCK \n",
      "\n",
      "    Return only the generic medication name, manufacturer/laboratory, importer, dosage, and packaging quantity of the OCR text, don't add addresses or any labeling. Write NOT FOUND if any info is missing. Return them seperated by |.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jandrik\\Documents\\MyFILES\\Programming\\Python Files\\Programs\\vino\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:540: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jandrik\\Documents\\MyFILES\\Programming\\Python Files\\Programs\\vino\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:545: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jandrik\\Documents\\MyFILES\\Programming\\Python Files\\Programs\\vino\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:562: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[126], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLevothyroxine sodium Euthyrox 50 mcg Tablet Thyroid Hormone Replacement CK R Imported by Merck Inc. 36th Floor,The Finance Center 26th Street corner 9th Avenue, Bonifacio Global City,Taguig 100 Tablets MERCK\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m extracted_result \u001b[38;5;241m=\u001b[39m extract_info_from_ocr(result)\n\u001b[0;32m      3\u001b[0m extracted_result\n",
      "Cell \u001b[1;32mIn[125], line 19\u001b[0m, in \u001b[0;36mextract_info_from_ocr\u001b[1;34m(ocr_text)\u001b[0m\n\u001b[0;32m     16\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer([input_text], return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Call generate on the inputs\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m out \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs,\n\u001b[0;32m     21\u001b[0m     max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m96\u001b[39m,\n\u001b[0;32m     22\u001b[0m     streamer\u001b[38;5;241m=\u001b[39mTextStreamer(tokenizer\u001b[38;5;241m=\u001b[39mtokenizer, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m     23\u001b[0m     pad_token_id\u001b[38;5;241m=\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39meos_token_id,\n\u001b[0;32m     24\u001b[0m     do_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     25\u001b[0m )\n\u001b[0;32m     27\u001b[0m extracted_query \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(out)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m#extracted_query = extracted_query[extracted_query.index('<|im_end|>\\n<|im_start|>system\\n')+len('<|im_end|>\\n<|im_start|>system\\n'):]\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m#extracted_query = extracted_query.replace('<|im_end|>', '')\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jandrik\\Documents\\MyFILES\\Programming\\Python Files\\Programs\\vino\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Jandrik\\Documents\\MyFILES\\Programming\\Python Files\\Programs\\vino\\Lib\\site-packages\\transformers\\generation\\utils.py:1914\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   1906\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   1907\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1908\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[0;32m   1909\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   1910\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1911\u001b[0m     )\n\u001b[0;32m   1913\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[1;32m-> 1914\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample(\n\u001b[0;32m   1915\u001b[0m         input_ids,\n\u001b[0;32m   1916\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[0;32m   1917\u001b[0m         logits_warper\u001b[38;5;241m=\u001b[39mprepared_logits_warper,\n\u001b[0;32m   1918\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[0;32m   1919\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   1920\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[0;32m   1921\u001b[0m         streamer\u001b[38;5;241m=\u001b[39mstreamer,\n\u001b[0;32m   1922\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1923\u001b[0m     )\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[0;32m   1926\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[0;32m   1927\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1928\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config, device\u001b[38;5;241m=\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   1929\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample\n\u001b[0;32m   1930\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1931\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Jandrik\\Documents\\MyFILES\\Programming\\Python Files\\Programs\\vino\\Lib\\site-packages\\transformers\\generation\\utils.py:2651\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[0;32m   2648\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[0;32m   2650\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[1;32m-> 2651\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\n\u001b[0;32m   2652\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs,\n\u001b[0;32m   2653\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   2654\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   2655\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   2656\u001b[0m )\n\u001b[0;32m   2658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[0;32m   2659\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jandrik\\Documents\\MyFILES\\Programming\\Python Files\\Programs\\vino\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Jandrik\\Documents\\MyFILES\\Programming\\Python Files\\Programs\\vino\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jandrik\\Documents\\MyFILES\\Programming\\Python Files\\Programs\\vino\\Lib\\site-packages\\transformers\\models\\qwen2\\modeling_qwen2.py:1221\u001b[0m, in \u001b[0;36mQwen2ForCausalLM.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[0;32m   1218\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m   1220\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[1;32m-> 1221\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[0;32m   1222\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1223\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   1224\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   1225\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m   1226\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[0;32m   1227\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m   1228\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1229\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   1230\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1231\u001b[0m     cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[0;32m   1232\u001b[0m )\n\u001b[0;32m   1234\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1235\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[1;32mc:\\Users\\Jandrik\\Documents\\MyFILES\\Programming\\Python Files\\Programs\\vino\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Jandrik\\Documents\\MyFILES\\Programming\\Python Files\\Programs\\vino\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jandrik\\Documents\\MyFILES\\Programming\\Python Files\\Programs\\vino\\Lib\\site-packages\\transformers\\models\\qwen2\\modeling_qwen2.py:1023\u001b[0m, in \u001b[0;36mQwen2Model.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m   1013\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m   1014\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1020\u001b[0m         cache_position,\n\u001b[0;32m   1021\u001b[0m     )\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1023\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m decoder_layer(\n\u001b[0;32m   1024\u001b[0m         hidden_states,\n\u001b[0;32m   1025\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mcausal_mask,\n\u001b[0;32m   1026\u001b[0m         position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   1027\u001b[0m         past_key_value\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m   1028\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1029\u001b[0m         use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m   1030\u001b[0m         cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[0;32m   1031\u001b[0m     )\n\u001b[0;32m   1033\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\Jandrik\\Documents\\MyFILES\\Programming\\Python Files\\Programs\\vino\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Jandrik\\Documents\\MyFILES\\Programming\\Python Files\\Programs\\vino\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jandrik\\Documents\\MyFILES\\Programming\\Python Files\\Programs\\vino\\Lib\\site-packages\\transformers\\models\\qwen2\\modeling_qwen2.py:777\u001b[0m, in \u001b[0;36mQwen2DecoderLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[0;32m    775\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m    776\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[1;32m--> 777\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(hidden_states)\n\u001b[0;32m    778\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[0;32m    780\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (hidden_states,)\n",
      "File \u001b[1;32mc:\\Users\\Jandrik\\Documents\\MyFILES\\Programming\\Python Files\\Programs\\vino\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Jandrik\\Documents\\MyFILES\\Programming\\Python Files\\Programs\\vino\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jandrik\\Documents\\MyFILES\\Programming\\Python Files\\Programs\\vino\\Lib\\site-packages\\transformers\\models\\qwen2\\modeling_qwen2.py:186\u001b[0m, in \u001b[0;36mQwen2MLP.forward\u001b[1;34m(self, hidden_state)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_state):\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_fn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgate_proj(hidden_state)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup_proj(hidden_state))\n",
      "File \u001b[1;32mc:\\Users\\Jandrik\\Documents\\MyFILES\\Programming\\Python Files\\Programs\\vino\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Jandrik\\Documents\\MyFILES\\Programming\\Python Files\\Programs\\vino\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jandrik\\Documents\\MyFILES\\Programming\\Python Files\\Programs\\vino\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result = \"'DONOTACCEPT IF SEAL 100 TABLETS IS BROKEN Allopurinol Llanol@ 100 mg Tablet Antigout R Manufactured by AMHERST LABORATORIES, INC. UNILAB Pharma Campus, Barangay Mamplasan Binan Laguna Philippines for UNILAB, Inc. No.66 United Street Mandaluyong CityMetro ManilaPhilippines'\"\n",
    "extracted_result = extract_info_from_ocr(result)\n",
    "extracted_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAllopurinol|Amherst Laboratories, Inc.|100 mg|100 tablets'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "fda_df = pd.read_csv('FDA_ALL.csv')\n",
    "rx_df = pd.read_csv('RX_ALL.csv')\n",
    "\n",
    "\n",
    "def match_with_fda(match_string, category=None, indexes=None):\n",
    "    matches = []\n",
    "    scores = []\n",
    "\n",
    "    if indexes is None:\n",
    "        indexes = list(range(len(fda_df)))\n",
    "\n",
    "    for i in indexes:\n",
    "        \n",
    "        if category is None:\n",
    "            medication_entry = str(fda_df.iloc[i]['Generic Name']) + str(fda_df.iloc[i]['Brand Name']) + str(fda_df.iloc[i]['Manufacturer']) + str(fda_df.iloc[i]['Dosage Strength'])  + str(fda_df.iloc[i]['Packaging'])\n",
    "        else:\n",
    "            medication_entry = str(fda_df.iloc[i][category])\n",
    "        score = fuzz.token_set_ratio(medication_entry.lower(), match_string.lower())\n",
    "\n",
    "        matches.append(fda_df.iloc[i]['INDEX'])\n",
    "        scores.append(score)\n",
    "    \n",
    "    matches, scores = zip(*sorted(zip(matches, scores), key=lambda x: x[1], reverse=True))\n",
    "    return matches, scores\n",
    "\n",
    "def match_with_rx(match_string):\n",
    "    matches = []\n",
    "    scores = []\n",
    "\n",
    "    for i in range(len(rx_df)):\n",
    "        \n",
    "        medication_entry = str(rx_df.iloc[i]['Drug_Name'])\n",
    "        score = fuzz.ratio(medication_entry.lower(), match_string.lower())\n",
    "        matches.append(rx_df.iloc[i]['INDEX'])\n",
    "        scores.append(score)\n",
    "    \n",
    "    matches, scores = zip(*sorted(zip(matches, scores), key=lambda x: x[1], reverse=True))\n",
    "    return matches, scores\n",
    "\n",
    "def get_info(match_string, limit=3):\n",
    "    fda_matches, fda_scores = match_with_fda(match_string=match_string)\n",
    "    matches = []\n",
    "\n",
    "    for match, score in zip(fda_matches[:limit], fda_scores[:limit]):\n",
    "        match_entry = dict(fda_df.iloc[match])\n",
    "        match_entry['match_score'] = score\n",
    "        generic_name = match_entry['Generic Name']\n",
    "        rx_matches, _ = match_with_rx(generic_name)\n",
    "        best_rx_match = dict(rx_df.iloc[rx_matches[0]])\n",
    "        match_entry['rx_info'] = best_rx_match\n",
    "        matches.append(match_entry)\n",
    "\n",
    "    return matches\n",
    "\n",
    "def get_info2(match_string, top_n=10, limit=3):\n",
    "    search_terms = match_string.split('|')\n",
    "    search_categories = ['Generic Name', 'Manufacturer', 'Dosage Strength', 'Packaging']\n",
    "\n",
    "    #filtered_scores = [0 for _ in range(len(fda_df))]\n",
    "    filtered_matches = list(range(len(fda_df)))\n",
    "\n",
    "    # for term, cat in zip(search_terms, search_categories):\n",
    "    #     matches, scores = match_with_fda(term, cat, filtered_matches)\n",
    "    #     filtered_matches, filtered_scores = matches[:top_n], scores[:top_n]\n",
    "    #     cumm_scores = list(np.array(scores[:top_n]) + np.array(filtered_scores[:top_n]))\n",
    "    #     filtered_matches, filtered_scores = matches[:top_n], cumm_scores[:top_n]\n",
    "        \n",
    "    # filtered_scores = list(np.array(filtered_scores)/len(search_categories))\n",
    "\n",
    "    weights = np.array([0.3, 0.3, 0.2, 0.2])  # Weights for each category\n",
    "    filtered_scores = np.zeros(top_n)  # Initialize scores\n",
    "\n",
    "    for i, (term, cat) in enumerate(zip(search_terms, search_categories)):\n",
    "        matches, scores = match_with_fda(term, cat, filtered_matches)\n",
    "        scores = np.array(scores[:top_n]) * weights[i]  # Apply weight\n",
    "        filtered_scores += scores  # Accumulate weighted scores\n",
    "        filtered_matches = matches[:top_n]  # Keep track of filtered matches\n",
    "\n",
    "    filtered_scores = list(filtered_scores)  # Convert back to list if needed\n",
    "\n",
    "\n",
    "    matches = []\n",
    "\n",
    "    for match, score in zip(filtered_matches[:limit], filtered_scores[:limit]):\n",
    "        match_entry = dict(fda_df.iloc[match])\n",
    "        match_entry['match_score'] = score\n",
    "        generic_name = match_entry['Generic Name']\n",
    "        rx_matches, _ = match_with_rx(generic_name)\n",
    "        best_rx_match = dict(rx_df.iloc[rx_matches[0]])\n",
    "        match_entry['rx_info'] = best_rx_match\n",
    "        matches.append(match_entry)\n",
    "\n",
    "    return matches\n",
    "\n",
    "#print(get_info('Allopurinol Llanole 100 mg Tablet Amherst Laboratories, Inc. Allopurinol'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'INDEX': 69,\n",
       "  'Registration Number': 'DR-X8671',\n",
       "  'Generic Name': 'Allopurinol',\n",
       "  'Brand Name': 'Llanol',\n",
       "  'Dosage Strength': '300 mg',\n",
       "  'Dosage Form': 'Tablet',\n",
       "  'Classification': 'Prescription Drug (RX)',\n",
       "  'Packaging': \"Aluminum foil strip x 4's (Box of 100's)\",\n",
       "  'Pharmacologic Category': '-',\n",
       "  'Manufacturer': 'Amherst Laboratories, Inc.',\n",
       "  'Country of Origin': 'Philippines',\n",
       "  'Trader': 'UNILAB, Inc.',\n",
       "  'Importer': nan,\n",
       "  'Distributor': nan,\n",
       "  'Application Type': '-',\n",
       "  'Issuance Date': '11-May-20',\n",
       "  'Expiry Date': '30-May-25',\n",
       "  'match_score': 88.6,\n",
       "  'rx_info': {'INDEX': 313,\n",
       "   'Drug_Name': 'Allopurinol (Zyloprim)',\n",
       "   'URL': 'https://www.rxlist.com/zyloprim-drug.htm'}},\n",
       " {'INDEX': 67,\n",
       "  'Registration Number': 'DR-X7781',\n",
       "  'Generic Name': 'Allopurinol',\n",
       "  'Brand Name': 'Purinase',\n",
       "  'Dosage Strength': '300 mg',\n",
       "  'Dosage Form': 'Tablet',\n",
       "  'Classification': 'Prescription Drug (RX)',\n",
       "  'Packaging': \"Foil strip x 10's (Box of 50's)\",\n",
       "  'Pharmacologic Category': '-',\n",
       "  'Manufacturer': 'Amherst Laboratories, Inc.',\n",
       "  'Country of Origin': 'Philippines',\n",
       "  'Trader': 'UNILAB, INC.',\n",
       "  'Importer': nan,\n",
       "  'Distributor': nan,\n",
       "  'Application Type': '-',\n",
       "  'Issuance Date': '22-Jan-21',\n",
       "  'Expiry Date': '1-Oct-25',\n",
       "  'match_score': 87.4,\n",
       "  'rx_info': {'INDEX': 313,\n",
       "   'Drug_Name': 'Allopurinol (Zyloprim)',\n",
       "   'URL': 'https://www.rxlist.com/zyloprim-drug.htm'}},\n",
       " {'INDEX': 143,\n",
       "  'Registration Number': 'DR-XY17277',\n",
       "  'Generic Name': 'Allopurinol',\n",
       "  'Brand Name': 'Loricid',\n",
       "  'Dosage Strength': '300 mg',\n",
       "  'Dosage Form': 'Oral Tablet',\n",
       "  'Classification': 'Prescription Drug (RX)',\n",
       "  'Packaging': \"foil strip x 10's\",\n",
       "  'Pharmacologic Category': 'ANTI-GOUT',\n",
       "  'Manufacturer': \"DRUGMAKER'S LABORATORIES, INC.\",\n",
       "  'Country of Origin': 'PHILIPPINES',\n",
       "  'Trader': 'LITTMANN DRUG CORP.',\n",
       "  'Importer': nan,\n",
       "  'Distributor': nan,\n",
       "  'Application Type': '-',\n",
       "  'Issuance Date': '20-Jun-22',\n",
       "  'Expiry Date': '19-Jun-27',\n",
       "  'match_score': 83.8,\n",
       "  'rx_info': {'INDEX': 313,\n",
       "   'Drug_Name': 'Allopurinol (Zyloprim)',\n",
       "   'URL': 'https://www.rxlist.com/zyloprim-drug.htm'}},\n",
       " {'INDEX': 12,\n",
       "  'Registration Number': 'DR-273',\n",
       "  'Generic Name': 'Allopurinol',\n",
       "  'Brand Name': 'Zyloprim',\n",
       "  'Dosage Strength': '100 mg',\n",
       "  'Dosage Form': 'Tablet',\n",
       "  'Classification': 'Prescription Drug (RX)',\n",
       "  'Packaging': 'Blister Pack',\n",
       "  'Pharmacologic Category': 'Antigout',\n",
       "  'Manufacturer': 'Aspen Bad Oldesloe GmbH',\n",
       "  'Country of Origin': 'Germany',\n",
       "  'Trader': nan,\n",
       "  'Importer': 'Aspen Philippines, Inc.',\n",
       "  'Distributor': nan,\n",
       "  'Application Type': 'Automatic Renewal',\n",
       "  'Issuance Date': '3-Aug-22',\n",
       "  'Expiry Date': '3-Oct-27',\n",
       "  'match_score': 76.10000000000001,\n",
       "  'rx_info': {'INDEX': 313,\n",
       "   'Drug_Name': 'Allopurinol (Zyloprim)',\n",
       "   'URL': 'https://www.rxlist.com/zyloprim-drug.htm'}},\n",
       " {'INDEX': 32,\n",
       "  'Registration Number': 'DR-7571',\n",
       "  'Generic Name': 'Allopurinol',\n",
       "  'Brand Name': 'Llanol',\n",
       "  'Dosage Strength': '100 mg',\n",
       "  'Dosage Form': 'Tablet',\n",
       "  'Classification': 'Prescription Drug (Rx)',\n",
       "  'Packaging': \"Aluminum Foil Strip x 4's\",\n",
       "  'Pharmacologic Category': 'Antigout',\n",
       "  'Manufacturer': 'Amherst laboratories, Inc.',\n",
       "  'Country of Origin': 'Philippines',\n",
       "  'Trader': 'UNILAB, Inc.',\n",
       "  'Importer': nan,\n",
       "  'Distributor': nan,\n",
       "  'Application Type': 'Renewal',\n",
       "  'Issuance Date': '26-May-22',\n",
       "  'Expiry Date': '30-May-27',\n",
       "  'match_score': 62.4,\n",
       "  'rx_info': {'INDEX': 313,\n",
       "   'Drug_Name': 'Allopurinol (Zyloprim)',\n",
       "   'URL': 'https://www.rxlist.com/zyloprim-drug.htm'}}]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_info2('', 5, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
